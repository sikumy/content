---
id: "cai-ia-ciberseguridad"
title: "CAI, el futuro de la IA en ciberseguridad"
author: "luis-javier-navarrete"
publishedDate: 2025-05-12
updatedDate: 2025-05-12
image: "https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-0.webp"
description: "Descubre CAI, el framework open-source de IA para pentesting automatizado: resultados reales en HTB, PortSwigger y bug bounties, capacidades ofensivas y defensivas revolucionarias."
categories:
  - "miscellaneous"
draft: false
featured: false
lang: "es"
---

Seguro que estÃ¡is oyendo hablar de IA en ciberseguridad por todas partes. Que si detecta _malware_, que si analiza logs... pero Â¿quÃ© hay de la parte _offensive_? Como creadores de **CAI (Cybersecurity AI)**, llevamos tiempo trabajando en llevar la IA al siguiente nivel: automatizar el _pentesting_ y la bÃºsqueda de _bugs_ de forma seria. Y sÃ­, creemos que el futuro ya estÃ¡ tocando a la puerta.

Hoy no vamos a hablar solo de teorÃ­a. Vamos a contaros quÃ© es CAI, nuestro _framework open-source_, y sobre todo, vamos a mostraros con datos y ejemplos (Â¡incluyendo _machines_ de HTB y labs de PortSwigger!) por quÃ© pensamos que esto va a cambiar las reglas del juego.

- [El Pain Point: Â¿Por QuÃ© Necesitamos Algo como CAI?](#el-pain-point-por-quÃ©-necesitamos-algo-como-cai)
- [Â¿QuÃ© es CAI? Our Baby, Open Source](#quÃ©-es-cai-our-baby-open-source)
- [Capabilities: Â¿QuÃ© Sabe Hacer CAI?](#capabilities-quÃ©-sabe-hacer-cai)
- [Resultados Reales: Where the Magic Happens](#resultados-reales-where-the-magic-happens)
- [Sobre los LLMs y lo que Dicen los Vendors...](#sobre-los-llms-y-lo-que-dicen-los-vendors)
- [Â¿Para QuiÃ©n Mola CAI?](#para-quiÃ©n-mola-cai)
- [Entonces, Â¿Le Damos una Oportunidad a CAI?](#entonces-le-damos-una-oportunidad-a-cai)
- [Get Involved!](#get-involved)

![Framework CAI de ciberseguridad con IA](https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-1.avif)

## El Pain Point: Â¿Por QuÃ© Necesitamos Algo como CAI?

Antes de meternos en harina, pongÃ¡monos en contexto. El panorama actual tiene sus _issues_:

1. **Talent Gap:** Faltan _pentesters_ y _security researchers_.
2. **Costes:** AuditorÃ­as serias y programas de _bug bounty_ no son baratos, y muchas _pymes_ se quedan fuera.
3. **Walled Gardens en Bug Bounty:** Plataformas como HackerOne o Bugcrowd centralizan mucho, lo cual no siempre es ideal para todos.
4. **Los Malos tambiÃ©n Usan IA:** Los _adversaries_ no se duermen. Necesitamos herramientas que escalen.

CAI naciÃ³ de la necesidad de abordar esto: un _framework_ para crear agentes de IA especializados que hagan el trabajo sucio (y a veces no tan sucio) de forma mÃ¡s rÃ¡pida, barata y accesible.

## Â¿QuÃ© es CAI? Our Baby, Open Source

CAI no es una simple herramienta, es un **framework agente-cÃ©ntrico**, _lightweight_ y, sÃ­, **open-source** (lo tenÃ©is en GitHub, link al final). EstÃ¡ pensado para construir _cybersecurity agents_ que hagan tareas especÃ­ficas.

Imagina que puedes montar tu propio equipo de _AI pentesters_. La arquitectura mola bastante, se basa en:

- **Agentes:** PequeÃ±as IAs enfocadas (uno para _web recon_, otro para _binary exploitation_, etc.).
- **Tools:** Se integra con las herramientas que ya usas: Nmap, Gobuster, Frida, Hashcat, Burp, Ghidra (Â¡gracias al _Model Context Protocol_!), Impacket, etc. El agente decide quÃ© lanzar.
- **Patterns:** Arquitecturas para coordinar agentes. Tenemos un _Red Team Agent_ para _pentesting_, un _Bug Bounty Hunter_ para _vuln hunting_, y Â¡ojo!, tambiÃ©n un **_Blue Team Agent_**. Este Ãºltimo se enfoca en la defensa: monitorizaciÃ³n, respuesta a incidentes, _vulnerability assessment_ desde la perspectiva del defensor...
- **Human-In-The-Loop (HITL):** Â¡Esto es CLAVE! No creemos en la autonomÃ­a total (todavÃ­a). Con un Ctrl+C puedes parar al agente, darle _feedback_, corregirlo... La colaboraciÃ³n humano-IA es el presente.

![Arquitectura del framework CAI](https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-2.avif)

## Capabilities: Â¿QuÃ© Sabe Hacer CAI?

SegÃºn nuestras pruebas y _R&D_ _(Research and Development)_:

1. **Automatiza la Kill Chain Ofensiva:** Desde el _recon_ y _scanning_, pasando por la _exploit_, hasta _post-exploitation_ (_privesc_, _lateral movement_) y _reporting_.
2. **Automatiza la Defensa (con Mentalidad Ofensiva):** CAI no solo ataca. Con los _Blue Team Agents_, puede automatizar tareas defensivas como _vulnerability assessments_ continuos o _incident response_ bÃ¡sico. Pero lo interesante es que lo hace **entendiendo cÃ³mo piensa un atacante**.
3. **Revienta CTFs (y Labs):** Se come _challenges_ de web, _reversing_, _pwn_, _forensics_, _crypto_... y como veremos, Â¡tambiÃ©n los labs de PortSwigger!
4. **Hace SAST (Static Analysis):** Analiza _source code_ directamente y encuentra _bugs_ en segundos/minutos.
5. **Bug Bounty Ready:** DiseÃ±ado para encontrar _bugs_ reales en entornos productivos.
6. **Flexible & Extensible:** Es _open source_, modular... _Sky's the limit_.
7. **Speed & Cost:** Reduce tiempos y costes de forma brutal.

[![Demo de CAI en Asciinema](https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-3.svg)](https://asciinema.org/a/713487) 

## Resultados Reales: Where the Magic Happens

Ok, basta de charla. Â¿Funciona o no? AquÃ­ van los datos duros de nuestras _benchmarks_ y pruebas:

- **CTFs vs Humanos:**
    - En 54 _challenges_ variados, CAI fue **11x mÃ¡s rÃ¡pido** y **156x mÃ¡s barato** de media.
    - DestrozÃ³ en _forensics_ (938x mÃ¡s rÃ¡pido), _reversing_ (774x) y _robotics_ (741x).
    - Le costÃ³ mÃ¡s en _pwn_ y _crypto_ avanzados.

![Benchmarks de CAI contra humanos en CTFs](https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-4.avif)

- **Resolviendo MÃ¡quinas y Labs Reales:**
    - **Hack The Box (HTB):** CAI automatiza toda la _killchain_. En 7 dÃ­as, se metiÃ³ en el **Top 30 de EspaÃ±a y Top 500 mundial**. Aunque en _mÃ¡quinas_ complejas el _First Blood_ humano suele ser mÃ¡s rÃ¡pido, la capacidad de CAI para correr mÃºltiples instancias en paralelo es una ventaja enorme.
    - **Ejemplo Concreto: MÃ¡quina AD de HTB (Â¡Esto es Oro!)**: Para que veÃ¡is cÃ³mo piensa y se adapta CAI, os contamos cÃ³mo reventÃ³ una mÃ¡quina de Active Directory bastante puÃ±etera:
        - **Olfateando y Encontrando la Pista ğŸ•µï¸â€â™‚ï¸:** _nmap_ rÃ¡pido -> DC Windows. smbclient -> Share support-tools -> UserInfo.exe. Â¡Sospechoso!
        
        - **Magia con el Binario âœ¨:** El .exe no soltaba las _creds_ LDAP fÃ¡cil. Un script normal se habrÃ­a bloqueado. CAI no. DescompilÃ³ con monodis, vio el XOR cutre (clave â€œarmandoâ€) y Â¡ZAS! ContraseÃ±a LDAP lista. Â¡Pura adaptaciÃ³n!
        
        - **Del Dominio al Usuario ğŸšª:** Con las _creds_ LDAP, ldapdomaindump. Â¿El hallazgo? Pass de support en texto plano ğŸ¤¦â€â™‚ï¸. Acceso WinRM vÃ­a crackmapexec (porque otras _tools_ como _evil-winrm_ fallaron y CAI supo cambiar de estrategia).
        
        - **Show de Active Directory Automatizado ğŸ‘‘ğŸ¤–:** Â¡La especialidad de CAI! DetectÃ³ la vÃ­a de ataque RBCD (_Resource-Based Constrained Delegation_). El entorno era inestable, los scripts PowerShell fallaban. Un enfoque determinista se habrÃ­a atascado. **La SoluciÃ³n de CAI (Inteligencia sobre herramientas):** UsÃ³ impacket (getuserspns.py, getnthash.py, secretsdump.py) de forma inteligente para explotar la RBCD y obtener acceso como Administrator.
        
        - **Resiliencia: Incluso Contra el Propio Kali Linux ğŸŒªï¸:** El sistema donde corrÃ­a CAI (nuestro Kali) empezÃ³ a dar errores: dependencias rotas, problemas de conexiÃ³n... Cualquier enfoque tradicional habrÃ­a colapsado. CAI no: identificÃ³ los fallos, resolviÃ³ conflictos de dependencias, reparÃ³ servicios y continuÃ³ el ataque sin pausa. Â¡Nada lo detuvo! ğŸ”¥
    
    - **Â¿Por QuÃ© CAI es Diferente (y Mejor) en estos casos? ğŸ˜**No es una secuencia rÃ­gida de comandos. Es una **inteligencia que orquesta herramientas**. Donde un script determinista falla ante un error o un entorno "raro", CAI:
        - **Analiza:** Entiende _por quÃ©_ algo falla.
        - **Se Adapta:** Elige _tools_ alternativas (netexec en vez de evil-winrm, atexec en vez de psexec).
        - **Resuelve:** Soluciona problemas del entorno (DNS, variables, Â¡hasta errores en el propio Kali!).
        - **Automatiza lo Complejo:** Un ataque a AD de principio a fin, sorteando obstÃ¡culos.

<video controls src="https://files.catbox.moe/mi6oow.mp4"></video>

- **PortSwigger Web Security Academy:** Se ventila _challenges_ de decenas de vulnerabilidades web en distintos entornos de forma autÃ³noma. Ideal para automatizar pruebas web.
- **AnÃ¡lisis EstÃ¡tico (SAST) en AcciÃ³n:** Encuentra SQLi en archivos .php _sin ejecutar nada_, solo leyendo el cÃ³digo.

![AnÃ¡lisis estÃ¡tico SAST con CAI](https://cdn.deephacking.tech/i/posts/cai-ia-ciberseguridad/cai-ia-ciberseguridad-5.avif)

- **Competiciones (Live CTFs):**
    - **"AI vs Human" CTF:** CAI quedÃ³ **1Âº entre las IAs** y **Top 20 mundial**, llevÃ¡ndose $750. PodÃ©is ver el artÃ­culo de HackTheBox en el siguiente enlace:
        - [AI vs Human: CTF results show AI agents can rival top hackers](https://www.hackthebox.com/blog/ai-vs-human-ctf-hack-the-box-results)
    - **"Cyber Apocalypse CTF 2025":** Puesto 22Âº en 3 horas (entre +8000 equipos).
- **Bug Bounties - La Prueba de Fuego:**
    - Experimento de una semana:
        - _No Profesionales:_ Encontraron **6 bugs vÃ¡lidos** (CVSS 4.3-7.4).
        - _Profesionales:_ Encontraron **4 bugs** (CVSS 4.3-7.5).
        - **Takeaway:** Â¡Resultados similares! CAI realmente **democratiza** el _bug hunting_ y el _security testing_.

## Sobre los LLMs y lo que Dicen los Vendors...

Hicimos _benchmarks_ con varios LLMs (Claude 3.7 Sonnet nos dio los mejores resultados _so far_). Creemos que algunos _vendors_ grandes estÃ¡n siendo algo conservadores al hablar de las capacidades _offensive_ de sus modelos. Nuestros resultados con CAI muestran que pueden hacer bastante mÃ¡s de lo que a veces se admite.

## Â¿Para QuiÃ©n Mola CAI?

- **Red Teams / Pentesters:** Para automatizar y acelerar.
- **Security Researchers / Bug Hunters:** Pros (para eficiencia) y _newbies_ (Â¡para empezar!).
- **Empresas (Especially SMEs):** Para _self-assessments_ continuos y asequibles.
- **Blue Teams:** Con el _Blue Team Agent_ para _monitoring_, _response_ y _vuln assessment_ continuo, entendiendo la perspectiva del atacante.
- **Academics / Researchers:** Plataforma _open source_ para investigar IA + Cyber.
- **Devs / DevOps:** Para integrar _SAST_ rÃ¡pido en el _pipeline_.

## Entonces, Â¿Le Damos una Oportunidad a CAI?

Â¡Totalmente! CAI es un proyecto **open source** con resultados que hablan por sÃ­ solos. Ha competido, ha ganado pasta, ha reventado _labs_, mÃ¡quinas y ha ayudado a gente _random_ a encontrar _bugs_ reales. Y no olvidemos que tambiÃ©n ayuda a automatizar la **defensa**, pero desde un punto de vista prÃ¡ctico y ofensivo: saber cÃ³mo te pueden atacar para defenderte mejor.

Lo de **democratizar** el acceso a _security testing_ avanzado (tanto _offensive_ como _defensive assessment_) es, para nosotros, lo mÃ¡s potente.

Obviamente, no es magia. La autonomÃ­a 100% tiene lÃ­mites. El _HITL_ es fundamental. Pero como _tool_ para **aumentar capacidades** y **automatizar**, el potencial es gigantesco.

## Get Involved!

Si te mola la idea, quieres probarlo o contribuir:

- **GitHub Repo:** [Repositorio oficial de CAI en GitHub](https://github.com/aliasrobotics/cai)
- **Discord Community:** [Ãšnete a la comunidad de CAI en Discord](https://discord.gg/fnUFcTaQAC)
- **Paper:** [Paper de investigaciÃ³n de CAI en arXiv](https://arxiv.org/pdf/2504.06017v2)

Trastea, mira quÃ© hace, y cuÃ©ntanos. QuizÃ¡s tu prÃ³ximo _bug_ lo encuentres con un _AI buddy_.

Â¡Happy Hacking! ğŸ˜
